{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: Classification (Part 2) and Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name: Matthew Wei (mswei2)\n",
    "\n",
    "### Due Sept 29th, 2023 11:59 PM\n",
    "\n",
    "**Logistics and Lab Submission**\n",
    "\n",
    "Upload the pdf and code to Gradescope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What You Will Need To Know For This Lab**\n",
    "\n",
    "This lab covers a few more basic classifiers which can be used for M-ary classification:\n",
    "- Naive Bayes\n",
    "\n",
    "as well as cross-validation, a tool for model selection and assessment.\n",
    " \n",
    "\n",
    "Remember in many applications, the end goal is not always \"run a classifier\", like in a homework problem, but is to use the output of the classifier in the context of the problem at hand (e.g. detecting spam, identifying cancer, etc.). Because of this, some of our Engineering Design-type questions are designed to get you to think about the entire design problem at a high level.\n",
    "\n",
    "\n",
    "**Warning: Do not train on your test sets. You will automatically get zero points**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preamble (don't change this)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "%pylab inline\n",
    "import numpy as np\n",
    "from sklearn import neighbors\n",
    "from sklearn import svm\n",
    "#from sklearn import cross_validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import genfromtxt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Spam Detection (70 points)\n",
    "\n",
    "In this problem, you will be constructing a crude spam detector. As you all know, when you receive an e-mail, it can be divided into one of two types: ham (useful mail, label $-1$) and spam (junk mail, label $+1$). In the [olden days](http://www.paulgraham.com/spam.html), people tried writing a bunch of rules to detect spam. However, it was quickly seen that machine learning approaches work fairly well for a little bit of work. \n",
    "\n",
    "You will be designing a spam detector by applying some of the classification techniques you learned in class to a batch of emails used to train and test [SpamAssassin](http://spamassassin.apache.org/), a leading anti-spam software package. \n",
    "\n",
    "Let the *vocabulary* of a dataset be a list of all terms occuring in a data set. So, for example, a vocabulary could be [\"cat\",\"dog\",\"chupacabra\", \"aerospace\", ...]. \n",
    "\n",
    "Our features will be based only the frequencies of terms in our vocabulary occuring in the e-mails (such an approach is called a *bag of words* approach, since we ignore the positions of the terms in the emails). The $j$-th feature is the number of times term $j$ in the vocabulary occurs in the email. If you are interested in further details on this model, you can see Chapters 6 and 13 in [Manning's Book](http://nlp.stanford.edu/IR-book/).\n",
    "\n",
    "You will use the following classifiers in this problem:\n",
    "- sklearn.naive_bayes.BernoulliNB (Naive Bayes Classifier with Bernoulli Model)\n",
    "- sklearn.naive_bayes.MultinomialNB (Naive Bayes Classifier with Multinomial Model)\n",
    "- sklearn.svm.LinearSVC (Linear Support Vector Machine)\n",
    "- sklearn.neighbors.KNeighborsClassifier (1-Nearest Neighbor Classifier)\n",
    "\n",
    "In the context of the Bernoulli Model for Naive Bayes, scikit-learn will binarize the features by interpretting the $j$-th feature to be $1$ if the $j$-th term in the vocabulary occurs in the email and $0$ otherwise. This is a categorical Naive Bayes model, with binary features. While we did not discuss the multinomial model in class, it operates directly on the frequencies of terms in the vocabulary, and is discussed in Section 13.2 in [Manning's Book](http://nlp.stanford.edu/IR-book/) (though you do not need to read this reference). Both the Bernoulli and Multinomial models are commonly used for Naive Bayes in text classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sample Ham email is:\n",
    "\n",
    "    From nic@starflung.com  Mon Jun 24 17:06:54 2002\n",
    "    Return-Path: 7910726.0.27May2002215326@mp.opensrs.net\n",
    "    Delivery-Date: Tue May 28 02:53:28 2002\n",
    "    Received: from mp.opensrs.net (mp.opensrs.net [216.40.33.45]) by\n",
    "        dogma.slashnull.org (8.11.6/8.11.6) with ESMTP id g4S1rSe14718 for\n",
    "        <zzz@spamassassin.taint.org>; Tue, 28 May 2002 02:53:28 +0100\n",
    "    Received: (from popensrs@localhost) by mp.opensrs.net (8.9.3/8.9.3) id\n",
    "        VAA04361; Mon, 27 May 2002 21:53:26 -0400\n",
    "    Message-Id: <7910726.0.27May2002215326@mp.opensrs.net>\n",
    "    Date: Mon, 27 May 2002 21:53:26 -0500 (EST)\n",
    "    From: \"Starflung NIC\" <nic@starflung.com>\n",
    "    To: <zzz@spamassassin.taint.org>\n",
    "    Subject: Automated 30 day renewal reminder 2002-05-27\n",
    "    X-Keywords: \n",
    "\n",
    "    The following domains that are registered as belonging\n",
    "    to you are due to expire within the next 60 days. If\n",
    "    you would like to renew them, please contact\n",
    "    nic@starflung.com; otherwise they will be deactivated\n",
    "    and may be registered by another.\n",
    "\n",
    "\n",
    "    Domain Name, Expiry Date\n",
    "    nutmegclothing.com, 2002-06-26\n",
    "    \n",
    "    \n",
    "A sample Spam email is: \n",
    "\n",
    "    From jjj@mymail.dk  Fri Aug 23 11:03:31 2002\n",
    "    Return-Path: <jjj@mymail.dk>\n",
    "    Delivered-To: zzzz@localhost.example.com\n",
    "    Received: from localhost (localhost [127.0.0.1])\n",
    "        by phobos.labs.example.com (Postfix) with ESMTP id 478B54415C\n",
    "        for <zzzz@localhost>; Fri, 23 Aug 2002 06:02:57 -0400 (EDT)\n",
    "    Received: from mail.webnote.net [193.120.211.219]\n",
    "        by localhost with POP3 (fetchmail-5.9.0)\n",
    "        for zzzz@localhost (single-drop); Fri, 23 Aug 2002 11:02:57 +0100 (IST)\n",
    "    Received: from smtp.easydns.com (smtp.easydns.com [205.210.42.30])\n",
    "        by webnote.net (8.9.3/8.9.3) with ESMTP id IAA08912;\n",
    "        Fri, 23 Aug 2002 08:13:36 +0100\n",
    "    From: jjj@mymail.dk\n",
    "    Received: from mymail.dk (unknown [61.97.34.233])\n",
    "        by smtp.easydns.com (Postfix) with SMTP\n",
    "        id 7484A2F85C; Fri, 23 Aug 2002 03:13:31 -0400 (EDT)\n",
    "    Reply-To: <jjj@mymail.dk>\n",
    "    Message-ID: <008c61d64eed$6184e5d5$4bc22de3@udnugg>\n",
    "    To: bbr_hooten@yahoo.com\n",
    "    Subject: HELP WANTED.  WORK FROM HOME REPS.\n",
    "    MiME-Version: 1.0\n",
    "    Content-Type: text/plain;\n",
    "        charset=\"iso-8859-1\"\n",
    "    X-Priority: 3 (Normal)\n",
    "    X-MSMail-Priority: Normal\n",
    "    X-Mailer: Microsoft Outlook, Build 10.0.2616\n",
    "    Importance: Normal\n",
    "    Date: Fri, 23 Aug 2002 03:13:31 -0400 (EDT)\n",
    "    Content-Transfer-Encoding: 8bit\n",
    "\n",
    "    Help wanted.  We are a 14 year old fortune 500 company, that is\n",
    "    growing at a tremendous rate.  We are looking for individuals who\n",
    "    want to work from home.\n",
    "\n",
    "    This is an opportunity to make an excellent income.  No experience\n",
    "    is required.  We will train you.\n",
    "\n",
    "    So if you are looking to be employed from home with a career that has\n",
    "    vast opportunities, then go:\n",
    "\n",
    "    http://www.basetel.com/wealthnow\n",
    "\n",
    "    We are looking for energetic and self motivated people.  If that is you\n",
    "    than click on the link and fill out the form, and one of our\n",
    "    employement specialist will contact you.\n",
    "\n",
    "    To be removed from our link simple go to:\n",
    "\n",
    "    http://www.basetel.com/remove.html\n",
    "\n",
    "\n",
    "    1349lmrd5-948HyhJ3622xXiM0-290VZdq6044fFvN0-799hUsU07l50\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will load the data. Our dataset has a bit over 9000 emails, with about 25% of them being spam. We will use 50% of them as a training set, 25% of them as a validation set and 25% of them as a test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of emails\n",
    "spamfiles=glob.glob('./Spam/*')\n",
    "hamfiles=glob.glob('./Ham/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we will split the files into the training, validation and test sets.\n",
    "\n",
    "np.random.seed(seed=222017) # seed the RNG for repeatability\n",
    "\n",
    "fnames=np.asarray(spamfiles+hamfiles)\n",
    "nfiles=fnames.size\n",
    "labels=np.ones(nfiles)\n",
    "labels[len(spamfiles):]=-1\n",
    "\n",
    "# Randomly permute the files we have\n",
    "idx=np.random.permutation(nfiles)\n",
    "fnames=fnames[idx]\n",
    "labels=labels[idx]\n",
    "\n",
    "#Split the file names into which set they belong to\n",
    "tname=fnames[:int(nfiles/2)]\n",
    "trainlabels=labels[:int(nfiles/2)]\n",
    "vname=fnames[int(nfiles/2):int(nfiles*3/4)]\n",
    "vallabels=labels[int(nfiles/2):int(nfiles*3/4)]\n",
    "tename=fnames[int(3/4*nfiles):]\n",
    "testlabels=labels[int(3/4*nfiles):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Get our Bag of Words Features from the data\n",
    "bow = CountVectorizer(input='filename',encoding='iso-8859-1',binary=False)\n",
    "traindata=bow.fit_transform(tname)\n",
    "valdata=bow.transform(vname)\n",
    "testdata=bow.transform(tename)\n",
    "print (\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $100$ most and least common terms in the vocabulary are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 most common terms:  slashnull,dogma,ist,thu,not,lists,cnet,mail,wed,as,html,have,click,jmason,exmh,00,are,align,freshrpms,or,mailman,date,text,mon,message,12,postfix,type,arial,users,bgcolor,ie,rpm,linux,version,22,be,taint,your,mailto,sourceforge,admin,content,20,color,table,jm,on,aug,border,127,example,face,href,this,nbsp,gif,09,subject,10,img,src,sep,it,that,0100,spamassassin,height,esmtp,is,size,xent,fork,you,tr,www,in,list,11,br,width,received,localhost,id,of,and,org,by,with,net,for,td,http,2002,font,from,3d,to,the,com \n",
      "\n",
      "100 least common terms:  g6mn17405760,e17titx,e17tvdy,e17ueb2,e17vjs8,e17vjsf,e17w5r4,e17wchv,e17wcmr,s4tkh2qxhrdntbervcuydvpgt4frugzlf3xwvohcrdtxohcfpaziiaed0ne9lw5,e17wosd,e17wosk,e17wssb,e17titf,e17wsyl,e17xbmd,e17xd4y,e17xlhj,e17yawz,s4lyze220qd,e17yozl,e17ysm1,e17ysna,e17ysox,e17ywux,e17z5re,e17z65d,e17wved,e17tfo0,e17texc,e17stjj,e17kazn,e17kb3f,e17kb3l,e17kba2,e17kcfg,e17kkxb,e17kxx7,e17kxxd,e17lk0h,e17lzkx,e17m2xi,e17mbzo,e17mpr7,e17n4br,e17n8od,e17nmuf,e17oai5,e17owlg,e17owlz,e17pfia,e17pfih,e17r7cf,e17rqza,e17rqzi,e17s52j,e17s6q9,e17sd3a,e17zimu,e17zl6i,e18bs5u,e18ec44161,e1n_n,e1pyognhf88zoewompdrqazaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa,s42bvq,s3zy0uqn9cxgumxzswr1e,e1s_jim_mac_gearailt,e1t,e1xwdo3b1k3wvr1u6cyugmvhm1nnyssndv2knuhw4g,s3wul4rjqofkdbzdhdtzxxnb005aaaaaa,e208716f77,e208e2940b3,e20c8406ff,s3w3ibekx4my0f8afuy,s3ulb6cl,e2178f6d01a70dfbdf9c84c4dcaf58dc,e22,e22432940aa,e224536,e226e294098,e22ab2d42c,e23,e23917,e23a916f1e,s3qjh,e240,e240merc,e241b6184464107168656739bf96c6b9,e242f2940ef,e1l_,e17k4ao,e1l1o9q,e1irt,e18gf17,e18hpmg,e18ifxm,e193416fea,e1amfeffcsliuttecieokbirfye5ds7mqt6dpbmltqjmwz5kzz5qvkvkvknb0i8hihpnwqro1z3a,e1b2916f03,e1bf816efc\n"
     ]
    }
   ],
   "source": [
    "counts=np.reshape(np.asarray(np.argsort(traindata.sum(axis=0))),-1)\n",
    "vocab=np.reshape(np.asarray(bow.get_feature_names_out()),-1)\n",
    "print (\"100 most common terms: \" , ','.join(str(s) for s in vocab[counts[-100:]]), \"\\n\")\n",
    "print (\"100 least common terms: \" , ','.join(str(s) for s in vocab[counts[:100]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will have our training data in `traindata` (with labels in `trainlabels`), validation data in `valdata` (with labels in `vallabels`) and test data in `testdata` (with labels in `testlabels`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the following classifiers **(10 points each)**:\n",
    "- sklearn.naive_bayes.BernoulliNB (Naive Bayes Classifier with Bernoulli Model)\n",
    "- sklearn.naive_bayes.MultinomialNB (Naive Bayes Classifier with Multinomial Model)\n",
    "- sklearn.svm.LinearSVC (Linear Support Vector Machine)\n",
    "- sklearn.neighbors.KNeighborsClassifier (as a 1-Nearest Neighbor Classifier)\n",
    "\n",
    "In this question, you are required to finish the followings:\n",
    "1. Train on the training data in `traindata` with corresponding labels `trainlabels`. Use the default parameters, unless otherwise noted.\n",
    "2. Report Training Error.\n",
    "3. Report Validation Error.\n",
    "4. Report the time it takes to fit the classifier (i.e. time to perform xxx.fit(X,y)).\n",
    "5. Report the time it takes to run the classifier on the validation data (i.e. time to perform xxx.predict(X,y)).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB Cassifier:\n",
      "Training Error: 0.034\n",
      "Validation Error: 0.055\n",
      "Fitting Time: 0.05107 sec\n",
      "Predicting Time: 4.61699 sec\n",
      "\n",
      "MultinomialNB Classifier:\n",
      "Training Error: 0.019\n",
      "Validation Error: 0.027\n",
      "Fitting Time: 0.02905 sec\n",
      "Predicting Time: 4.61699 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matt3\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC Classifier:\n",
      "Training Error: 0.000\n",
      "Validation Error: 0.011\n",
      "Fitting Time: 1.39243 sec\n",
      "Predicting Time: 4.61699 sec\n",
      "\n",
      "NN Classifier:\n",
      "Training Error: 0.000\n",
      "Validation Error: 0.016\n",
      "Fitting Time: 0.02122 sec\n",
      "Predicting Time: 4.61699 sec\n"
     ]
    }
   ],
   "source": [
    "# Put your code here\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#q1 = Question1()\n",
    "classifier_list = [\"BernoulliNB\", \"MultinomialNB\", \"LinearSVC\", \"NN\"]\n",
    "\n",
    "classifier = BernoulliNB()\n",
    "start = time.time()\n",
    "classifier.fit(traindata,trainlabels)\n",
    "end = time.time()\n",
    "fittingTime = end - start\n",
    "predictLabels = classifier.predict(traindata)\n",
    "trainingError = np.mean(trainlabels!=predictLabels)\n",
    "start = time.time()\n",
    "predictLabels = classifier.predict(valdata)\n",
    "end = time.time()\n",
    "predictingTime = end_point - start_point\n",
    "validationError = np.mean(vallabels!=predictLabels)\n",
    "\n",
    "print(\"BernoulliNB Cassifier:\")\n",
    "print(\"Training Error: %.3f\" % trainingError)\n",
    "print(\"Validation Error: %.3f\" % validationError)\n",
    "print(\"Fitting Time: %.5f sec\" % fittingTime)\n",
    "print(\"Predicting Time: %.5f sec\" % valPredictingTime)\n",
    "print(\"\")\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "start = time.time()\n",
    "classifier.fit(traindata,trainlabels)\n",
    "end = time.time()\n",
    "fittingTime = end - start\n",
    "predictLabels = classifier.predict(traindata)\n",
    "trainingError = np.mean(trainlabels!=predictLabels)\n",
    "start = time.time()\n",
    "predictLabels = classifier.predict(valdata)\n",
    "end = time.time()\n",
    "predictingTime = end_point - start_point\n",
    "validationError = np.mean(vallabels!=predictLabels)\n",
    "\n",
    "print(\"MultinomialNB Classifier:\")\n",
    "print(\"Training Error: %.3f\" % trainingError)\n",
    "print(\"Validation Error: %.3f\" % validationError)\n",
    "print(\"Fitting Time: %.5f sec\" % fittingTime)\n",
    "print(\"Predicting Time: %.5f sec\" % valPredictingTime)\n",
    "print(\"\")\n",
    "\n",
    "classifier = LinearSVC()\n",
    "start = time.time()\n",
    "classifier.fit(traindata,trainlabels)\n",
    "end = time.time()\n",
    "fittingTime = end - start\n",
    "predictLabels = classifier.predict(traindata)\n",
    "trainingError = np.mean(trainlabels!=predictLabels)\n",
    "start = time.time()\n",
    "predictLabels = classifier.predict(valdata)\n",
    "end = time.time()\n",
    "predictingTime = end_point - start_point\n",
    "validationError = np.mean(vallabels!=predictLabels)\n",
    "\n",
    "print(\"LinearSVC Classifier:\")\n",
    "print(\"Training Error: %.3f\" % trainingError)\n",
    "print(\"Validation Error: %.3f\" % validationError)\n",
    "print(\"Fitting Time: %.5f sec\" % fittingTime)\n",
    "print(\"Predicting Time: %.5f sec\" % valPredictingTime)\n",
    "print(\"\")\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=1)\n",
    "start = time.time()\n",
    "classifier.fit(traindata,trainlabels)\n",
    "end = time.time()\n",
    "fittingTime = end - start\n",
    "predictLabels = classifier.predict(traindata)\n",
    "trainingError = np.mean(trainlabels!=predictLabels)\n",
    "start = time.time()\n",
    "predictLabels = classifier.predict(valdata)\n",
    "end = time.time()\n",
    "predictingTime = end_point - start_point\n",
    "validationError = np.mean(vallabels!=predictLabels)\n",
    "\n",
    "print(\"NN Classifier:\")\n",
    "print(\"Training Error: %.3f\" % trainingError)\n",
    "print(\"Validation Error: %.3f\" % validationError)\n",
    "print(\"Fitting Time: %.5f sec\" % fittingTime)\n",
    "print(\"Predicting Time: %.5f sec\" % valPredictingTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extra (not evaluated):** Based on the results of this problem and knowledge of the application at hand (spam filtering), pick one of the classifiers in this problem and describe how you would use it as part of a spam filter for the University of Illinois email system. Sketch out a system design at a very high level -- how you would train the spam filter to deal with new threats, would you filter everyone's email jointly, etc. You may get some inspiration from the [girls and boys](https://gmail.googleblog.com/2007/10/how-our-spam-filter-works.html) at [Gmail](https://gmail.googleblog.com/2015/07/the-mail-you-want-not-spam-you-dont.html), the [chimps at MailChimp](http://kb.mailchimp.com/delivery/spam-filters/about-spam-filters) or other places."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that calculates the confusion matrix. . **(10 points)**\n",
    "\n",
    "Run the classifier you selected in the previous part of the problem on the test data. The following code displays the test error and the output of the function. **(10 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: 0.010693\n",
      "True Positives: 615.0 False Positive: 20.0\n",
      "False Negative: 5.0 True Negatives: 1698.0\n",
      "True Positive Rate :  0.9919354838709677\n",
      "False Positive Rate:  0.011641443538998836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matt3\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Put your code here\n",
    "classifier = LinearSVC()\n",
    "classifier.fit(traindata,trainlabels)\n",
    "estimatedlabels = classifier.predict(testdata)\n",
    "testError = np.mean(testlabels!=estimatedlabels)\n",
    "confusionmatrix = np.zeros((2,2))\n",
    "confusionmatrix[0,0]=np.sum(np.logical_and(testlabels==1, estimatedlabels==1))\n",
    "confusionmatrix[0,1]=np.sum(np.logical_and(testlabels==-1, estimatedlabels==1))\n",
    "confusionmatrix[1,0]=np.sum(np.logical_and(testlabels==1, estimatedlabels==-1))\n",
    "confusionmatrix[1,1]=np.sum(np.logical_and(testlabels==-1, estimatedlabels==-1))\n",
    "print(\"Test Error: %3f\" % testError)\n",
    "print (\"True Positives:\", confusionmatrix[0,0], \"False Positive:\", confusionmatrix[0,1])\n",
    "print (\"False Negative:\", confusionmatrix[1,0], \"True Negatives:\", confusionmatrix[1,1])\n",
    "print (\"True Positive Rate : \", confusionmatrix[0,0]/(confusionmatrix[0,0] + confusionmatrix[1,0]))\n",
    "print (\"False Positive Rate: \", confusionmatrix[0,1]/(confusionmatrix[0,1] + confusionmatrix[1,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check, you should observe that your true positive rate is above 0.95 (i.e. highly sensitive)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Problem 2: Cross-Validation (50 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will load some data (acquired from <a href=\"http://www.cs.ubc.ca/~murphyk/\">K.P. Murphy</a>'s <a href=\"https://github.com/probml/pmtk3\"> PMTK tookit</a>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem2_tmp= genfromtxt('p2.csv', delimiter=',')\n",
    "\n",
    "# Randomly reorder the data\n",
    "np.random.seed(seed=2217) # seed the RNG for repeatability\n",
    "idx=np.random.permutation(problem2_tmp.shape[0])\n",
    "problem2_tmp=problem2_tmp[idx]\n",
    "\n",
    "#The training data which you will use is called \"traindata\"\n",
    "traindata=problem2_tmp[:200,:2]\n",
    "#The training labels are in \"labels\"\n",
    "trainlabels=problem2_tmp[:200,2]\n",
    "\n",
    "#The test data which you will use is called \"testdata\" with labels \"testlabels\"\n",
    "testdata=problem2_tmp[200:,:2]\n",
    "testlabels=problem2_tmp[200:,2]\n",
    "\n",
    "# You should not re-shuffle your data in your functions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function which implements $5$-fold cross-validation to estimate the error of a classifier with cross-validation with the 0,1-loss for k-Nearest Neighbors (kNN). \n",
    "\n",
    "You will be given as input:\n",
    "* A (N,d) numpy.ndarray of training data, *trainData* (with N divisible by 5)\n",
    "* A length $N$ numpy.ndarray of training labels, *trainLabels*\n",
    "* A number $k$, for which cross-validated error estimates will be outputted for $1,\\ldots,k$\n",
    "\n",
    "Your output will be a vector (represented as a numpy.ndarray) *err*, such that *err[i]* is the cross-validated estimate of using i neighbors (*err* will be of length $k+1$; the zero-th component of the vector will be meaningless). \n",
    "\n",
    "**For this problem, take your folds to be 0:N/5, N/5:2N/5, ..., 4N/5:N for cross-validation (In general, however, the folds should be randomly divided).**\n",
    "\n",
    "Use scikit-learn's sklearn.neighbors.KNeighborsClassifier to perform the training and classification for the kNN models involved.  <b>(25 points)</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that *calls the above function* and returns 1) the output from the previous function, 2) the number of neighbors within $1,\\ldots,30$ that minimizes the cross-validation error, and 3) the correponding minimum error. <b>(15 points)</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code helps you to visualize your result. It plots the cross-validation error with respect to the number of neighbors. Your best number of neighbors should be roughly at the middle of your err array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best number of neighbors is: 14\n",
      "The corresponding error is: 0.175\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#q2 = Question2()\n",
    "#err, k_min, err_min = q2.minimizer_K(traindata,trainlabels,30)\n",
    "N = traindata.shape[0]\n",
    "d = traindata.shape[1]\n",
    "traindatacross = []\n",
    "trainlabelcross = []\n",
    "for i in range(5):\n",
    "    traindatacross.append(np.delete(traindata, np.s_[int(i*N/5):int((i+1)*N/5)], 0))\n",
    "    trainlabelcross.append(np.delete(trainlabels, np.s_[int(i*N/5):int((i+1)*N/5)], 0))\n",
    "\n",
    "err = np.zeros(31)\n",
    "for i in range(1, 31):\n",
    "    model = KNeighborsClassifier(n_neighbors = i,weights='distance')\n",
    "    for j in range(5):\n",
    "        model.fit(traindatacross[j],trainlabelcross[j])\n",
    "        err[i]+=(1 - model.score(traindata[int(j*N/5):int((j+1)*N/5)], trainlabels[int(j*N/5):int((j+1)*N/5)]))/5\n",
    "\n",
    "def minimizer_K(kNN_errors):\n",
    "    k_min = np.argmin(kNN_errors[1: kNN_errors.shape[0]]) + 1\n",
    "    err_min = kNN_errors[k_min]\n",
    "    return (k_min, err_min)\n",
    "\n",
    "k_min, err_min = minimizer_K(err)\n",
    "    \n",
    "plot(np.arange(1,31),err[1:])\n",
    "xlabel('Number of Neighbors')\n",
    "ylabel('Cross-validation error')\n",
    "axis('tight')\n",
    "print(\"The best number of neighbors is:\", k_min)\n",
    "print(\"The corresponding error is:\", err_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a kNN model on the whole training data using the number of neighbors you found in the previous part of the question, and apply it to the test data. **(10 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test error is: 0.214\n"
     ]
    }
   ],
   "source": [
    "#_, testError = q2.classify(traindata, trainlabels, testdata, testlabels)\n",
    "classifier = KNeighborsClassifier(n_neighbors=k_min)\n",
    "classifier.fit(traindata, trainlabels)\n",
    "predtestlabels = classifier.predict(testdata)\n",
    "testError = np.mean(testlabels!=predtestlabels)\n",
    "\n",
    "print(\"The test error is:\", testError)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check, the test error should be around 0.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## And this concludes Lab 4! Congratulations!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3: Detecting Bad Sensors in Power System Monitoring\n",
    "\n",
    "In this lab, our goal is to detect bad sensor data measured on the IEEE 14 bus test\n",
    "system shown below. The power flow equations that couple the voltages and power flows are \n",
    "nonlinear in nature, as discussed in class. We will load the sensor data from the\n",
    "file 'sensorData14Bus.csv', and utilize SVM to perform the bad data detection.\n",
    "We aim to understand how various parameters such as the nature of the corrupt data,\n",
    "the number of corrupt data, etc., affect our abilities to classify the data.\n",
    "\n",
    "<img src=\"IEEE14bus.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, we need to call the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn import preprocessing, svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from IPython.display import Image\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data \n",
    "\n",
    "Load the sensor data from the IEEE 14 bus test system, that has 14 buses\n",
    " and 20 branches. The data has been generated by adding a small noise\n",
    " to feasible voltages and power flows.\n",
    "     \n",
    "     Columns 1-14 contain bus voltage magnitudes.\n",
    "     \n",
    "     Columns 15-28 contain bus voltage phase angles.\n",
    "     \n",
    "     Columns 29-48 contain real power flow on all branches.\n",
    "     \n",
    "     Columns 49-68 contain reactive power flow on all branches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sensor data on IEEE 14 bus system.\n",
      "Number of data points = 5000, number of features = 26\n"
     ]
    }
   ],
   "source": [
    "nBuses = 14\n",
    "nBranches = 20\n",
    "\n",
    "# Select the bus numbers you monitor. For convenience, we have selected it for you.\n",
    "# The '-1' makes them columns as per Python's convention of starting to number\n",
    "# from 0.\n",
    "busesToSample = np.array([1, 2, 5, 10, 13]) - 1\n",
    "columnsForBuses = np.concatenate((busesToSample, busesToSample + 14))\n",
    "\n",
    "# Select the branches that you monitor.\n",
    "branchesToSample = np.array([1, 3, 5, 10, 11, 15, 17, 20]) - 1\n",
    "columnsForBranches = np.concatenate((branchesToSample + 28,\n",
    "                                     branchesToSample + 48))\n",
    "\n",
    "# Load the sensor data from the file 'sensorData14Bus.csv' in 'X' from the columns\n",
    "# specified in 'columnsForBuses' and 'columnsForBranches'. The csv file is comma\n",
    "# separated. Read a maximum of 5000 lines. Make sure your data is a numpy array\n",
    "# with each column typecast as 'np.float32'.\n",
    "X = np.genfromtxt('sensorData14Bus.csv', dtype=np.float32, delimiter=',',\n",
    "                  usecols=np.concatenate((columnsForBuses, columnsForBranches)),\n",
    "                  max_rows=5000)\n",
    "\n",
    "nDataPoints = np.shape(X)[0]\n",
    "nFeatures = np.shape(X)[1]\n",
    "\n",
    "print(\"Loaded sensor data on IEEE 14 bus system.\")\n",
    "print(\"Number of data points = %d, number of features = %d\"\n",
    "      % (nDataPoints, nFeatures))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curroption Models \n",
    "\n",
    "Intentionally corrupt the first 'nCorrupt' rows of the data by adding\n",
    " a quantity to one or two sensor measurements that is not representative of\n",
    " our error model. We aim to study what nature of corruption is easier\n",
    " or difficult to detect.\n",
    " Specifically, we shall study 3 different models:\n",
    " \n",
    "     1. 'corruptionModel' = 1 : Add a random number with a bias to one of the measurements.\n",
    "     \n",
    "     2. 'corruptionModel' = 2 : Add a random number without bias to one of the measurements.\n",
    "     \n",
    "     3. 'corruptionModel' = 3 : Add a random number with a bias to both the measurements.\n",
    "     \n",
    "In all these cases, we will multiply the sensor data by either a uniform or a normal random number multiplied by 'multiplicationFactor'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a corruption model.\n",
    "nCorrupt = int(nDataPoints/3)\n",
    "corruptionModel = 1\n",
    "multiplicationFactor = 0.5\n",
    "\n",
    "# Choose which data to tamper with, that can be a voltage magnitude,\n",
    "# voltage phase angle, real power flow on a branch, reactive power flow\n",
    "# on a branch. We create functions to extract the relevant column to\n",
    "# corrupt the corresponding data in the 'ii'-th bus or branch.\n",
    "voltageMagnitudeColumn = lambda ii: ii\n",
    "\n",
    "voltageAngleColumn = lambda ii: ii + np.shape(busesToSample)[0]\n",
    "\n",
    "realPowerColumn = lambda ii: ii + 2*np.shape(busesToSample)[0]\n",
    "reactivePowerColumn = lambda ii: ii + 2*np.shape(busesToSample)[0] + np.shape(branchesToSample)[0]\n",
    "\n",
    "# Encode two different kinds of columns to corrupt.\n",
    "# Option 1: Corrupt real power columns only.\n",
    "# Option 2: Corrupt real power and voltage magnitude.\n",
    "columnsToCorruptOption = 2\n",
    "\n",
    "if columnsToCorruptOption == 1:\n",
    "    columnsToCorrupt = [realPowerColumn(1),\n",
    "                        realPowerColumn(2)]\n",
    "else:\n",
    "    columnsToCorrupt = [voltageMagnitudeColumn(0),\n",
    "                        realPowerColumn(1)]\n",
    "\n",
    "# Corrupt the data appropriately, given the options.\n",
    "for index in range(nCorrupt):\n",
    "\n",
    "    if corruptionModel == 1:\n",
    "        X[index, columnsToCorrupt[0]] \\\n",
    "            *= (1 + multiplicationFactor * np.random.rand())\n",
    "    elif corruptionModel == 2:\n",
    "        X[index, columnsToCorrupt[0]] \\\n",
    "            *= (1 + multiplicationFactor * np.random.randn())\n",
    "    else:\n",
    "        X[index, columnsToCorrupt[0]] \\\n",
    "            *= (1 + multiplicationFactor * np.random.rand())\n",
    "        X[index, columnsToCorrupt[1]] \\\n",
    "            *= (1 + multiplicationFactor * np.random.rand())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " It is always a good practice to scale your data to run SVM. Notice that we are\n",
    " cheating a little when we scale the entire data set 'X', because our training and\n",
    " test sets are derived from 'X'. Ideally, one would have to scale the training\n",
    " and test sets separately. Create the appropriate labels and shuffle the lists 'X' and 'Y' together.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = preprocessing.StandardScaler().fit_transform(X)\n",
    "\n",
    "# Create the labels as a column of 1's for the first 'nCorrupt' rows, and\n",
    "# 0's for the rest.\n",
    "Y = np.concatenate((np.ones(nCorrupt), np.zeros(nDataPoints-nCorrupt)))\n",
    "\n",
    "\n",
    "# Shuffle the features and the labels together.\n",
    "XY = list(zip(X, Y))\n",
    "np.random.shuffle(XY)\n",
    "X, Y = zip(*XY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Task 1 (10 points)\n",
    "\n",
    "Split the dataset into two parts: training and testing.\n",
    "Store the training set in the variables 'trainX' and 'trainY'.\n",
    " Store the testing set in the variables 'testX' and 'testY.\n",
    " Reserve 20% of the data for testing.\n",
    "The function 'train_test_split' may prove useful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here\n",
    "trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 (10 points)\n",
    "\n",
    " Define the support vector machine classifier and train on the variables 'trainX' and 'trainY'. Use the SVC library from sklearn.svm. Only specify three hyper-parameters: 'kernel', 'degree', and 'max_iter'. Limit the maximum number of iterations to 100000 at the most. Set the kernel to be a linear classifier first. You may have to change it to report the results with other kernels. The parameter 'degree' specifies the degree for polynomial kernels. This parameter is not used for other kernels. The functions 'svm.SVC' and 'fit' will prove useful.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;, max_iter=100000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;, max_iter=100000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear', max_iter=100000)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enter your code here\n",
    "svm_class = svm.SVC(kernel='linear', degree=3, max_iter=100000) \n",
    "svm_class.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 (10 points)\n",
    "\n",
    "Predict the labels on the 'testX' dataset and store them in 'predictY'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here\n",
    "predictY = svm_class.predict(testX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 (10 points)\n",
    "\n",
    "Print the 'classification_report' to see how well 'predictY' matches with 'testY'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.98       681\n",
      "         1.0       0.99      0.93      0.96       319\n",
      "\n",
      "    accuracy                           0.98      1000\n",
      "   macro avg       0.98      0.97      0.97      1000\n",
      "weighted avg       0.98      0.98      0.98      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Enter your code here\n",
    "print(classification_report(testY, predictY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print svm's internal accuracy score as a percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm's internal accuracy score = 97.7%\n"
     ]
    }
   ],
   "source": [
    "# Enter your code here\n",
    "print(f'svm\\'s internal accuracy score = {svm_class.score(testX, testY)*100.0}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5\n",
    "\n",
    "We would like to compare 'classification_report' with this score for various runs. Let us consider the following cases: \n",
    "\n",
    "### Case 1:\n",
    "\n",
    "Only have sensor measurements from the first 5 branches. Choose option 1 in the 'columnsToCorruptOption'. Examine how well linear kernels perform when 'corruptionModel' = 1, 'corruptionModel' = 2, and 'corruptionModel'= 3. In case linear kernels do not perform well, you may try 'rbf' or polynomial kernels with degree 2.\n",
    "\n",
    "### Case 2:\n",
    "\n",
    "Choose 'corruptionModel = 1' with 'linear' kernel. Does it pay to monitor voltage magnitudes than power flows? In other words, do you consistently get better results when you choose 'columnsToCorruptOption' as 2? Make these judgements using the average score of at least 5 runs.\n",
    "\n",
    "\n",
    "#### Your task is to investigate the above two cases. You may add a few 'Markdown' and 'Code' cells below with your comments, code, and results. You can also report your results as a pandas DataFrame. You are free to report your results in your own way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "corruptionModel =  1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      1.00      0.96       672\n",
      "         1.0       1.00      0.81      0.89       328\n",
      "\n",
      "    accuracy                           0.94      1000\n",
      "   macro avg       0.96      0.90      0.92      1000\n",
      "weighted avg       0.94      0.94      0.94      1000\n",
      "\n",
      "svm's internal accuracy score = 93.7%\n",
      "\n",
      "corruptionModel =  2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      1.00      0.89       652\n",
      "         1.0       1.00      0.53      0.70       348\n",
      "\n",
      "    accuracy                           0.84      1000\n",
      "   macro avg       0.90      0.77      0.79      1000\n",
      "weighted avg       0.87      0.84      0.82      1000\n",
      "\n",
      "svm's internal accuracy score = 83.8%\n",
      "\n",
      "corruptionModel =  3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      1.00      0.97       673\n",
      "         1.0       1.00      0.86      0.92       327\n",
      "\n",
      "    accuracy                           0.95      1000\n",
      "   macro avg       0.97      0.93      0.95      1000\n",
      "weighted avg       0.96      0.95      0.95      1000\n",
      "\n",
      "svm's internal accuracy score = 95.39999999999999%\n"
     ]
    }
   ],
   "source": [
    "# Function copied and pasted from above in code with modifications\n",
    "def corrupt(X, nCorrupt, corruptionModel, busesToSample, branchesToSample):\n",
    "    multiplicationFactor = 0.5\n",
    "    voltageMagnitudeColumn = lambda ii: ii\n",
    "    voltageAngleColumn = lambda ii: ii + np.shape(busesToSample)[0]\n",
    "    realPowerColumn = lambda ii: ii + 2*np.shape(busesToSample)[0]\n",
    "    reactivePowerColumn = lambda ii: ii + 2*np.shape(busesToSample)[0] + np.shape(branchesToSample)[0]\n",
    "    columnsToCorruptOption = 1\n",
    "    if columnsToCorruptOption == 1:\n",
    "        columnsToCorrupt = [realPowerColumn(1),\n",
    "                            realPowerColumn(2)]\n",
    "    else:\n",
    "        columnsToCorrupt = [voltageMagnitudeColumn(0),\n",
    "                            realPowerColumn(1)]\n",
    "    for index in range(nCorrupt):\n",
    "        if corruptionModel == 1:\n",
    "            X[index, columnsToCorrupt[0]] \\\n",
    "                *= (1 + multiplicationFactor * np.random.rand())\n",
    "        elif corruptionModel == 2:\n",
    "            X[index, columnsToCorrupt[0]] \\\n",
    "                *= (1 + multiplicationFactor * np.random.randn())\n",
    "        else:\n",
    "            X[index, columnsToCorrupt[0]] \\\n",
    "                *= (1 + multiplicationFactor * np.random.rand())\n",
    "            X[index, columnsToCorrupt[1]] \\\n",
    "                *= (1 + multiplicationFactor * np.random.rand())    \n",
    "            \n",
    "# Function reused from before\n",
    "def func(X, Y, nCorrupt):\n",
    "    X = preprocessing.StandardScaler().fit_transform(X)\n",
    "    Y = np.concatenate((np.ones(nCorrupt), np.zeros(nDataPoints-nCorrupt)))\n",
    "    XY = list(zip(X, Y))\n",
    "    np.random.shuffle(XY)\n",
    "    X, Y = zip(*XY)\n",
    "    return X, Y\n",
    "\n",
    "for i in range(1,4):\n",
    "    # From also copied and pasted from above\n",
    "    busesToSample = np.array([1, 2, 5, 10, 13]) - 1\n",
    "    columnsForBuses = np.concatenate((busesToSample, busesToSample + 14))\n",
    "    branchesToSample = np.array([1, 2, 3, 4, 5]) - 1\n",
    "    columnsForBranches = np.concatenate((branchesToSample + 28,\n",
    "                                        branchesToSample + 48))\n",
    "    X = np.genfromtxt('sensorData14Bus.csv', dtype=np.float32, delimiter=',',\n",
    "                        usecols=np.concatenate((columnsForBuses, columnsForBranches)),\n",
    "                        max_rows=5000)\n",
    "    nDataPoints = np.shape(X)[0]\n",
    "    nFeatures = np.shape(X)[1]\n",
    "    nCorrupt = int(nDataPoints/3)\n",
    "    corrupt(X, nCorrupt, i, busesToSample, branchesToSample)\n",
    "    \n",
    "    X, Y = func(X, Y, nCorrupt)\n",
    "    trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.2)\n",
    "    svm_class = svm.SVC(kernel='rbf', max_iter=100000) # Tried rbf instead of linear\n",
    "    svm_class.fit(trainX, trainY)\n",
    "\n",
    "    predictY = svm_class.predict(testX)\n",
    "    print('\\ncorruptionModel = ', i)\n",
    "    print(classification_report(testY, predictY))\n",
    "    print(f'svm\\'s internal accuracy score = {svm_class.score(testX, testY)*100.0}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "The linear kernels vary in accuracy with model 3 being the most accurate and model 2 being the least accurate. Model 2 being the least accurate makes sense because it adds corruption without bias making it most inaccurate. Model 3 being the best also makes sense because more errors were available to train the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matt3\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\matt3\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\matt3\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\matt3\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columnsToCorruptOption =  1\n",
      "svm's average score = 75.44%\n",
      "\n",
      "columnsToCorruptOption =  2\n",
      "svm's average score = 97.50%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function copied and pasted from above in code with modifications with edits\n",
    "def corrupt(X, nCorrupt, corruptionModel, busesToSample, branchesToSample, columnsToCorruptOption):\n",
    "    multiplicationFactor = 0.5\n",
    "    voltageMagnitudeColumn = lambda ii: ii\n",
    "    voltageAngleColumn = lambda ii: ii + np.shape(busesToSample)[0]\n",
    "    realPowerColumn = lambda ii: ii + 2*np.shape(busesToSample)[0]\n",
    "    reactivePowerColumn = lambda ii: ii + 2*np.shape(busesToSample)[0] + np.shape(branchesToSample)[0]\n",
    "    if columnsToCorruptOption == 1:\n",
    "        columnsToCorrupt = [realPowerColumn(1),\n",
    "                            realPowerColumn(2)]\n",
    "    else:\n",
    "        columnsToCorrupt = [voltageMagnitudeColumn(0),\n",
    "                            realPowerColumn(1)]\n",
    "    for index in range(nCorrupt):\n",
    "        if corruptionModel == 1:\n",
    "            X[index, columnsToCorrupt[0]] \\\n",
    "                *= (1 + multiplicationFactor * np.random.rand())\n",
    "        elif corruptionModel == 2:\n",
    "            X[index, columnsToCorrupt[0]] \\\n",
    "                *= (1 + multiplicationFactor * np.random.randn())\n",
    "        else:\n",
    "            X[index, columnsToCorrupt[0]] \\\n",
    "                *= (1 + multiplicationFactor * np.random.rand())\n",
    "            X[index, columnsToCorrupt[1]] \\\n",
    "                *= (1 + multiplicationFactor * np.random.rand())    \n",
    "\n",
    "# Function mostly copied and pasted with the add of an extra loop and the average counter\n",
    "for i in range(1,3):\n",
    "    average = 0\n",
    "    for j in range(5):\n",
    "        busesToSample = np.array([1, 2, 5, 10, 13]) - 1\n",
    "        columnsForBuses = np.concatenate((busesToSample, busesToSample + 14))\n",
    "        branchesToSample = np.array([1, 3, 5, 10, 11, 15, 17, 20]) - 1\n",
    "        columnsForBranches = np.concatenate((branchesToSample + 28, branchesToSample + 48))\n",
    "        X = np.genfromtxt('sensorData14Bus.csv', dtype=np.float32, delimiter=',',\n",
    "                          usecols=np.concatenate((columnsForBuses, columnsForBranches)),\n",
    "                          max_rows=5000)\n",
    "        nDataPoints = np.shape(X)[0]\n",
    "        nFeatures = np.shape(X)[1]\n",
    "        nCorrupt = int(nDataPoints/3)\n",
    "        corrupt(X, nCorrupt, 1, busesToSample, branchesToSample, i)\n",
    "        \n",
    "        X, Y = func(X, Y, nCorrupt)\n",
    "        trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.2)\n",
    "        svm_class = svm.SVC(kernel='linear', max_iter=100000)\n",
    "        svm_class.fit(trainX, trainY)\n",
    "        predictY = svm_class.predict(testX)\n",
    "        average += svm_class.score(testX, testY)\n",
    "    print('columnsToCorruptOption = ', i)\n",
    "    print(f'svm\\'s average score = {average/nRuns*100:.2f}%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "columnsToCorruptOption 2 has a higher average score than option 1. Since option 2 corrupts more columns (voltage and real values), this means more corruption leads to a better classifier and estimation. This is also shown in case 1 where corription option 3 performed better than the other 2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
